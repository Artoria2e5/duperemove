- Store results of our search to speed up subsequent runs.
  - When writing hashes, store latest btrfs transaction id in the hash file (import find-new from btrfsprogs for this)
  - When reading hashes and we have a transaction id, do a scan of btrfs objects to see which inodes have changed.
    - Changed inodes get re-checksummed
    - Deleted inodes get their hashes removed
    - New inodes get checksummed
  - To tie this all together, we need to add an option (maybe simply called --hash-file?) which acts as a create-or-update
    mode for hash file usage. Now the user can run duperemove, with one command, on a regular basis and we'll automatically
    keep the hash database updated.

- Add an optional mode to do duplicate checking with resolution of extent
  owners.

- Allow checking for similar files by some criteria (approximate size,
  file magic type, file extension, etc)

- Wrap bytes <-> blocks conversions

- Possibly use mmap (with madvise) for the checksumming phase
